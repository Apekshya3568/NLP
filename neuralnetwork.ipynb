{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40312ef2-72b2-4bd1-8a40-7c560e71953d",
   "metadata": {},
   "source": [
    "Simple Neural Network for Text Classification using Keras, part of TensorFlow, to build a feedforward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bfd508-1f82-4b07-a7d3-3a68a7c4a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.13.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorflow) (2.4.1)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.1-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.18.0-cp312-cp312-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pc\\onedrive\\desktop\\nlp-code\\myvenv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "Using cached h5py-3.15.1-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "Using cached keras-3.13.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl (212 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp312-cp312-win_amd64.whl (312 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.12.19 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.13.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 protobuf-6.33.4 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 werkzeug-3.1.5 wheel-0.45.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f48ef-1f0b-4438-8af3-e246f7f74ca1",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7ce15e-6c8b-45e2-a94a-1f4cfd0766f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\OneDrive\\Desktop\\NLP-CODE\\myvenv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6030a-558b-4a3f-b5bb-919abcd61d73",
   "metadata": {},
   "source": [
    "Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3becbcc-d94b-4e25-80f5-661defea6000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\OneDrive\\Desktop\\NLP-CODE\\myvenv\\Lib\\site-packages\\sklearn\\datasets\\_base.py:1519: UserWarning: Retry downloading from url: https://ndownloader.figshare.com/files/5975967\n",
      "  warnings.warn(f\"Retry downloading from url: {remote.url}\")\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'comp.graphics']  # 2 classes for simplicity\n",
    "data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers','footers','quotes'))\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f9dc2-9c29-45e6-bada-f377c5ec4446",
   "metadata": {},
   "source": [
    "Vectorize Text (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc41895-d80d-4d2a-81e9-a58bda87fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_vec = tfidf.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b663c-1aec-4a71-998a-9b2b65a1bc78",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6ee69-6c4c-4ba3-a5d9-9a9e08b74ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74947ae8-1549-4005-a5fa-71a81c1ab380",
   "metadata": {},
   "source": [
    "Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cb015-8200-488c-b29b-b4d5522803c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer + first hidden layer\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Second hidden layer (optional)\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # binary classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f4b58-9739-4015-aafb-09be4e7503aa",
   "metadata": {},
   "source": [
    "Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0616776-0da4-406c-a5fb-46d75c41e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee435af-02c3-42df-96b1-341771dff17f",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc42b0-08b6-4ec2-90df-fa76d226fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43ced3-c25c-472f-86bd-00818056cd20",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90300cc-3e1a-44d3-bfad-6203c37ddd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc77dd-bb90-4069-8172-c2d471e21bdf",
   "metadata": {},
   "source": [
    "Predict New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6cad66-74ae-453a-958d-87ae6c7a0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "    vec = tfidf.transform([text])\n",
    "    prob = model.predict(vec)[0][0]\n",
    "    return \"Class 1 \" if prob>0.5 else \"Class 0 \"\n",
    "\n",
    "print(predict_text(\"Computer graphics is amazing!\"))\n",
    "print(predict_text(\"Religion is a philosophical topic.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
